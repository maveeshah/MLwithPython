{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Where does Yolo come from? Background\n",
    "To understand \"Yolo\" you must first know about computer vision and a little bit about it's history\n",
    "The art of making computer look at things and recognize, detect and diff is called computer vision\n",
    "it has been one of the most difficult attribute of learning for computers despite the fact that humans excel at it without much effort.\n",
    "There had been many efforts on the past to teach computers understanding the art of looking and interpreting things since the emergence of A.I in 1960s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why Yolo?\n",
    "There are many algorithms used for computer vision so why do we need YOLO?\n",
    "In the field of computer vision other algorithms performed very well but problem occured at the real time object detection or recognition as in cases of autonomous vehicle, this is where YOLO shines.\n",
    "YOLO is a state of the art computer vision algorithm that is faster then the fastest algorithms out there and doesn't fall behind in the accuracy field either"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How does it work?\n",
    "unlike previous attempts at Object detection algorithms used to process images thousands of time to make a prediction which at the end was quite time taking and also computationally expensive. Instead what yolo does is passes the images through algo just once as it's name says \"You Only Look Once\".\n",
    "- What it does is divides the image into grids of small cells\n",
    "- each cell predicts if some object is in there with a certain confidence level \n",
    "- then where is it\n",
    "- what class does it belong to <br />\n",
    "and then we set some threshold to drop the predictions with low confidences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prediction validation\n",
    "Yolo uses intersection over union approach to decide whether the prediction was right or not\n",
    "i.e the bounding boxes of prediction and actual target value are used to calculate Intersction over union \n",
    "IoU = Area of Intersection/ Area of Union <br />\n",
    "A certain threshold either discards or keeps the prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Non-Maximum Suppression\n",
    "In CV algorithms have a tendency of detecting an object not just once but many more times creating more than one bounding boxes around a single object, in YOLO nms is used to overcome that\n",
    "How nms works is :\n",
    "1. It looks at all the boxes around a single object and selects the one with heighest probability.\n",
    "2. The boxes which have high IoU with the current box are suppressed.\n",
    "3. Then it selects the one with next heighest probability/confidence.\n",
    "4. Recursive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Anchor boxes\n",
    "As discussed above if we went and applied that way on a picture that has two objects in a same grid it will only \n",
    "return one bounding box which isn't the case in reality hence anchor boxes come into play\n",
    "We define number of anchor boxes and so we get that many outputs outta each grid\n",
    "<br />\n",
    "![no anchor](no_anchor.png)\n",
    "![2 anchors used ](anchor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here,\n",
    "- pc defines whether an object is present in the grid or not (it is the confidence score)\n",
    "- bx, by, bh, bw specify the bounding box if there is an object( x,y being the center, h and w being height and width)\n",
    "- c1, c2, c3 represent the classes. incase of three classes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flattening \n",
    "Flatten means that anything greater than 1 dimension must be convert to 1D."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By now you should have understood what YOLO is and how it works, let's get to the coding now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Write down conf, nms thresholds,inp width/height\n",
    "confThreshold = 0.25\n",
    "nmsThreshold = 0.40\n",
    "inpWidth = 416\n",
    "inpHeight = 416\n",
    "\n",
    "#Load names of classes and turn that into a list\n",
    "classesFile = \"yolov3\"\n",
    "classes = None\n",
    "\n",
    "with open(classesFile,'rt') as f:\n",
    "    classes = f.read().rstrip('\\n').split('\\n')\n",
    "\n",
    "#Model configuration\n",
    "modelConf = 'yolov3.cfg'\n",
    "modelWeights = 'yolov3.weights'\n",
    "\n",
    "#Set up the net\n",
    "net = cv.dnn.readNetFromDarknet(modelConf, modelWeights)\n",
    "net.setPreferableBackend(cv.dnn.DNN_BACKEND_OPENCV)\n",
    "net.setPreferableTarget(cv.dnn.DNN_TARGET_CPU)\n",
    "\n",
    "#Process inputs\n",
    "winName = 'DL OD with OpenCV'\n",
    "cv.namedWindow(winName, cv.WINDOW_NORMAL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "def writeInCsv(imname, count):\n",
    "    with open(\"result.csv\",'a') as output:\n",
    "        output_data = csv.writer(output,delimiter = ',')\n",
    "        output_data.writerow([imname,count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter the input type \n",
      "V for video \n",
      "I for images \n",
      "0 for webcamI\n",
      "Image Name: q\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-0f4d53c26159>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[0mimgName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Image Name: \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     \u001b[0mframe\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimgName\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 86\u001b[1;33m     \u001b[0mblob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mblobFromImage\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;36m255\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0minpWidth\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minpHeight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcrop\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m     \u001b[0mnet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msetInput\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mblob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.1.2) C:\\projects\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:3720: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "def postprocess(frame, outs):\n",
    "    frameHeight = frame.shape[0]\n",
    "    frameWidth = frame.shape[1]\n",
    "\n",
    "    classIDs = []\n",
    "    confidences = []\n",
    "    boxes = []\n",
    "    count = 0\n",
    "\n",
    "    for out in outs:\n",
    "        for detection in out:         \n",
    "            scores = detection[5:]\n",
    "            classID = np.argmax(scores)\n",
    "            confidence = scores[classID]\n",
    "            if confidence > confThreshold:\n",
    "                centerX = int(detection[0] * frameWidth)\n",
    "                centerY = int(detection[1] * frameHeight)\n",
    "                width = int(detection[2]* frameWidth)\n",
    "                height = int(detection[3]*frameHeight)\n",
    "                left = int(centerX - width/2)\n",
    "                top = int(centerY - height/2)\n",
    "                if classes[classID] == 'person':\n",
    "                    classIDs.append(classID)\n",
    "                    confidences.append(float(confidence))\n",
    "                    boxes.append([left, top, width, height])\n",
    "\n",
    "    indices = cv.dnn.NMSBoxes (boxes,confidences, confThreshold, nmsThreshold )\n",
    "\n",
    "    indices = cv.dnn.NMSBoxes(boxes, confidences, confThreshold, nmsThreshold)\n",
    "    for i in indices:\n",
    "        i = i[0]\n",
    "        box = boxes[i]\n",
    "        left = box[0]\n",
    "        top = box[1]\n",
    "        width = box[2]\n",
    "        height = box[3]\n",
    "        count += 1\n",
    "        drawPred(classIDs[i], confidences[i], left, top, left + width, top + height,count)\n",
    "    return count\n",
    "\n",
    "def drawPred(classId, conf, left, top, right, bottom,count):\n",
    "    # Draw a bounding box.\n",
    "    cv.rectangle(frame, (left, top), (right, bottom), (255, 178, 50), 3)\n",
    "    label = '%.2f' % conf\n",
    "\n",
    "    # Get the label for the class name and its confidence\n",
    "    if classes:\n",
    "        assert (classId < len(classes))\n",
    "        label = '%s:%s:%s' % (classes[classId], label,count)\n",
    "\n",
    "    cv.putText(frame, label, (left,top), cv.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 1)\n",
    "\n",
    "def getOutputsNames(net):\n",
    "    # Get the names of all the layers in the network\n",
    "    layersNames = net.getLayerNames()\n",
    "   \n",
    "    # Get the names of the output layers, i.e. the layers with unconnected outputs\n",
    "    return [layersNames[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "                \n",
    "fileToInfer = input(\"Enter the input type \\nV for video \\nI for images \\n0 for webcam\")\n",
    "frame_num = 0\n",
    "if fileToInfer == '0':\n",
    "    cap = cv.VideoCapture(0)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    while cv.waitKey(1) < 0:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            print(\"video not captured\")\n",
    "            break\n",
    "        else:\n",
    "            blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop = False)\n",
    "\n",
    "            net.setInput(blob)\n",
    "            outs = net.forward(getOutputsNames(net))\n",
    "\n",
    "            count = postprocess(frame, outs)\n",
    "            #show the image\n",
    "            cv.imshow(winName, frame)\n",
    "            imgName = \"web_%s\"%frame_num\n",
    "            frame_num += 1\n",
    "            writeInCsv(imgName, count)\n",
    "elif fileToInfer == 'I':\n",
    "    imgName = input(\"Image Name: \")\n",
    "    frame = cv.imread(imgName)\n",
    "    blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop = False)\n",
    "\n",
    "    net.setInput(blob)\n",
    "    outs = net.forward (getOutputsNames(net))\n",
    "\n",
    "    count = postprocess(frame, outs)\n",
    "    #show the image\n",
    "    cv.imshow(winName, frame)\n",
    "    writeInCsv(imgName, count)\n",
    "else:\n",
    "    vidName = input(\"Video Name: \")\n",
    "    cap = cv.VideoCapture(vidName)\n",
    "    frame_width = int(cap.get(3))\n",
    "    frame_height = int(cap.get(4))\n",
    "    while cv.waitKey(1) < 0:\n",
    "        ret, frame = cap.read()\n",
    "        if ret == False:\n",
    "            print(\"video not captured\")\n",
    "            break\n",
    "        else:\n",
    "            blob = cv.dnn.blobFromImage(frame, 1/255, (inpWidth, inpHeight), [0,0,0], 1, crop = False)\n",
    "\n",
    "            net.setInput(blob)\n",
    "            outs = net.forward (getOutputsNames(net))\n",
    "\n",
    "            count = postprocess (frame, outs)\n",
    "            #show the image\n",
    "            cv.imshow(winName, frame)\n",
    "            imgName = \"%s:%s\"%(vidName,frame_num)\n",
    "            frame_num += 1\n",
    "            writeInCsv(imgName, count)\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
